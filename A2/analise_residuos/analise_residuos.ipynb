{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "273eeca4",
      "metadata": {},
      "source": [
        "# Análise de resíduos - Geral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "af03685c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.stats.diagnostic import normal_ad, acorr_ljungbox, het_arch\n",
        "from statsmodels.stats.stattools import durbin_watson\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from statsmodels.regression.linear_model import OLS\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "file_path = 'data_updated.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "3d195838",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResidualAnalysis:\n",
        "    \"\"\"Classe para análise de resíduos de modelos de séries temporais\"\"\"\n",
        "    \n",
        "    def __init__(self, model_name: str, residuals: np.ndarray, \n",
        "                 fitted_values: np.ndarray, actual_values: np.ndarray):\n",
        "        self.model_name = model_name\n",
        "        self.residuals = np.array(residuals)\n",
        "        self.fitted_values = np.array(fitted_values)\n",
        "        self.actual_values = np.array(actual_values)\n",
        "        self.analysis_results = {}\n",
        "        \n",
        "    def comprehensive_residual_analysis(self, lags: int = 20, save_path: Optional[str] = None) -> Dict:\n",
        "        \"\"\"Realiza análise completa dos resíduos\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ANÁLISE DE RESÍDUOS: {self.model_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        self._formal_tests(lags)\n",
        "        self._plot_comprehensive_analysis(lags, save_path)\n",
        "        self._print_diagnostic_summary()\n",
        "        \n",
        "        return self.analysis_results\n",
        "    \n",
        "    def _formal_tests(self, lags: int):\n",
        "        \"\"\"Executa testes estatísticos formais nos resíduos\"\"\"\n",
        "        try:\n",
        "            ad_stat, ad_pvalue = normal_ad(self.residuals)\n",
        "            self.analysis_results['normality_ad'] = {\n",
        "                'statistic': ad_stat, 'p_value': ad_pvalue, 'is_normal': ad_pvalue > 0.05\n",
        "            }\n",
        "        except:\n",
        "            self.analysis_results['normality_ad'] = {'statistic': np.nan, 'p_value': np.nan, 'is_normal': np.nan}\n",
        "        \n",
        "        try:\n",
        "            lb_test = acorr_ljungbox(self.residuals, lags=[lags], return_df=True)\n",
        "            self.analysis_results['ljung_box'] = {\n",
        "                'statistic': lb_test['lb_stat'].iloc[0], \n",
        "                'p_value': lb_test['lb_pvalue'].iloc[0], \n",
        "                'no_autocorr': lb_test['lb_pvalue'].iloc[0] > 0.05\n",
        "            }\n",
        "        except:\n",
        "            self.analysis_results['ljung_box'] = {'statistic': np.nan, 'p_value': np.nan, 'no_autocorr': np.nan}\n",
        "        \n",
        "        try:\n",
        "            arch_test = het_arch(self.residuals)\n",
        "            self.analysis_results['arch_test'] = {\n",
        "                'statistic': arch_test[0], 'p_value': arch_test[1], 'is_homoscedastic': arch_test[1] > 0.05\n",
        "            }\n",
        "        except:\n",
        "            self.analysis_results['arch_test'] = {'statistic': np.nan, 'p_value': np.nan, 'is_homoscedastic': np.nan}\n",
        "        \n",
        "        try:\n",
        "            dw_stat = durbin_watson(self.residuals)\n",
        "            self.analysis_results['durbin_watson'] = {\n",
        "                'statistic': dw_stat, 'no_autocorr': 1.5 <= dw_stat <= 2.5\n",
        "            }\n",
        "        except:\n",
        "            self.analysis_results['durbin_watson'] = {'statistic': np.nan, 'no_autocorr': np.nan}\n",
        "        \n",
        "        self.analysis_results['descriptive_stats'] = {\n",
        "            'mean': np.mean(self.residuals),\n",
        "            'std': np.std(self.residuals),\n",
        "            'skewness': stats.skew(self.residuals),\n",
        "            'kurtosis': stats.kurtosis(self.residuals),\n",
        "            'min': np.min(self.residuals),\n",
        "            'max': np.max(self.residuals),\n",
        "            'rmse': np.sqrt(np.mean(self.residuals**2)),\n",
        "            'mae': np.mean(np.abs(self.residuals)),\n",
        "            'mse': np.mean(self.residuals**2)\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            t_stat, p_value = stats.ttest_1samp(self.residuals, 0)\n",
        "            self.analysis_results['mean_test'] = {\n",
        "                't_statistic': t_stat, 'p_value': p_value, 'mean_zero': p_value > 0.05\n",
        "            }\n",
        "        except:\n",
        "            self.analysis_results['mean_test'] = {'t_statistic': np.nan, 'p_value': np.nan, 'mean_zero': np.nan}\n",
        "    \n",
        "    def _plot_comprehensive_analysis(self, lags: int, save_path: Optional[str]):\n",
        "        \"\"\"Gera gráficos de análise de resíduos\"\"\"\n",
        "        fig = plt.figure(figsize=(20, 12))\n",
        "        \n",
        "        plots = [\n",
        "            (1, 'Resíduos vs Tempo', lambda ax: self._plot_residuals_time(ax)),\n",
        "            (2, 'Distribuição dos Resíduos', lambda ax: self._plot_residuals_dist(ax)),\n",
        "            (3, 'Q-Q Plot', lambda ax: qqplot(self.residuals, line='s', ax=ax, alpha=0.7)),\n",
        "            (4, 'ACF dos Resíduos', lambda ax: plot_acf(self.residuals, lags=lags, ax=ax, alpha=0.05)),\n",
        "            (5, 'Resíduos vs Valores Ajustados', lambda ax: self._plot_residuals_vs_fitted(ax)),\n",
        "            (6, 'ACF dos Resíduos²', lambda ax: plot_acf(self.residuals**2, lags=lags, ax=ax, alpha=0.05)),\n",
        "            (7, 'PACF dos Resíduos', lambda ax: plot_pacf(self.residuals, lags=lags, ax=ax, alpha=0.05)),\n",
        "            (8, 'Resíduos Padronizados', lambda ax: self._plot_standardized_residuals(ax)),\n",
        "            (9, 'Resumo Estatístico', lambda ax: self._plot_stats_summary(ax))\n",
        "        ]\n",
        "        \n",
        "        for i, (pos, title, plot_func) in enumerate(plots):\n",
        "            ax = plt.subplot(3, 3, pos)\n",
        "            plot_func(ax)\n",
        "            plt.title(title)\n",
        "            plt.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.suptitle(f'Análise de Resíduos - {self.model_name}', fontsize=14, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        \n",
        "        plt.show()\n",
        "    \n",
        "    def _plot_residuals_time(self, ax):\n",
        "        plt.plot(self.residuals, 'o-', alpha=0.7, markersize=3)\n",
        "        plt.axhline(y=0, color='r', linestyle='--', alpha=0.8)\n",
        "        plt.xlabel('Tempo')\n",
        "        plt.ylabel('Resíduos')\n",
        "    \n",
        "    def _plot_residuals_dist(self, ax):\n",
        "        plt.hist(self.residuals, bins=25, density=True, alpha=0.7, color='skyblue')\n",
        "        xmin, xmax = plt.xlim()\n",
        "        x = np.linspace(xmin, xmax, 100)\n",
        "        p = stats.norm.pdf(x, np.mean(self.residuals), np.std(self.residuals))\n",
        "        plt.plot(x, p, 'r-', linewidth=2, label='Normal')\n",
        "        plt.xlabel('Resíduos')\n",
        "        plt.ylabel('Densidade')\n",
        "        plt.legend()\n",
        "    \n",
        "    def _plot_residuals_vs_fitted(self, ax):\n",
        "        plt.scatter(self.fitted_values, self.residuals, alpha=0.6)\n",
        "        plt.axhline(y=0, color='r', linestyle='--', alpha=0.8)\n",
        "        plt.xlabel('Valores Ajustados')\n",
        "        plt.ylabel('Resíduos')\n",
        "    \n",
        "    def _plot_standardized_residuals(self, ax):\n",
        "        standardized_residuals = (self.residuals - np.mean(self.residuals)) / np.std(self.residuals)\n",
        "        plt.plot(standardized_residuals, 'o-', alpha=0.7, markersize=3)\n",
        "        plt.axhline(y=0, color='r', linestyle='--', alpha=0.8)\n",
        "        plt.axhline(y=2, color='orange', linestyle='--', alpha=0.6, label='±2σ')\n",
        "        plt.axhline(y=-2, color='orange', linestyle='--', alpha=0.6)\n",
        "        plt.xlabel('Tempo')\n",
        "        plt.ylabel('Resíduos Padronizados')\n",
        "        plt.legend()\n",
        "    \n",
        "    def _plot_stats_summary(self, ax):\n",
        "        ax.axis('off')\n",
        "        stats_text = self._get_stats_text()\n",
        "        ax.text(0.1, 0.95, stats_text, transform=ax.transAxes, fontsize=10,\n",
        "                verticalalignment='top', fontfamily='monospace')\n",
        "    \n",
        "    def _get_stats_text(self) -> str:\n",
        "        stats = self.analysis_results\n",
        "        text = f\"Modelo: {self.model_name}\\n\"\n",
        "        text += f\"Média: {stats['descriptive_stats']['mean']:.4f}\\n\"\n",
        "        text += f\"Desvio Padrão: {stats['descriptive_stats']['std']:.4f}\\n\"\n",
        "        text += f\"Assimetria: {stats['descriptive_stats']['skewness']:.4f}\\n\"\n",
        "        text += f\"Curtose: {stats['descriptive_stats']['kurtosis']:.4f}\\n\"\n",
        "        text += f\"RMSE: {stats['descriptive_stats']['rmse']:.4f}\\n\"\n",
        "        text += f\"MAE: {stats['descriptive_stats']['mae']:.4f}\\n\\n\"\n",
        "        text += f\"Normalidade (AD): {stats['normality_ad']['p_value']:.3f}\\n\"\n",
        "        text += f\"Autocorr (Ljung-Box): {stats['ljung_box']['p_value']:.4f}\\n\"\n",
        "        text += f\"Heteroced (ARCH): {stats['arch_test']['p_value']:.4f}\\n\"\n",
        "        text += f\"Durbin-Watson: {stats['durbin_watson']['statistic']:.4f}\"\n",
        "        return text\n",
        "    \n",
        "    def _print_diagnostic_summary(self):\n",
        "        stats = self.analysis_results\n",
        "        print(\"\\nDIAGNÓSTICO DOS RESÍDUOS:\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        criteria = {\n",
        "            \" Média zero\": stats['mean_test']['mean_zero'],\n",
        "            \" Normalidade\": stats['normality_ad']['is_normal'],\n",
        "            \" Sem autocorrelação\": stats['ljung_box']['no_autocorr'],\n",
        "            \" Homocedasticidade\": stats['arch_test']['is_homoscedastic'],\n",
        "            \" Durbin-Watson OK\": stats['durbin_watson']['no_autocorr']\n",
        "        }\n",
        "        \n",
        "        print(f\"\\nERROS:\")\n",
        "        print(f\"  RMSE: {stats['descriptive_stats']['rmse']:.4f}\")\n",
        "        print(f\"  MAE:  {stats['descriptive_stats']['mae']:.4f}\")\n",
        "        print(f\"  MSE:  {stats['descriptive_stats']['mse']:.4f}\")\n",
        "        print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "77acb600",
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaselineModels:\n",
        "    @staticmethod\n",
        "    def fit_mean_model(train: pd.Series, test_length: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        mean_value = train.mean()\n",
        "        return np.full(test_length, mean_value), np.full(len(train), mean_value)\n",
        "    \n",
        "    @staticmethod\n",
        "    def fit_naive_model(train: pd.Series, test_length: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        last_value = train.iloc[-1]\n",
        "        return np.full(test_length, last_value), np.full(len(train), last_value)\n",
        "    \n",
        "    @staticmethod\n",
        "    def fit_drift_model(train: pd.Series, test_length: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        drift = (train.iloc[-1] - train.iloc[0]) / max(len(train) - 1, 1)\n",
        "        predictions = train.iloc[-1] + drift * np.arange(1, test_length + 1)\n",
        "        fitted = train.iloc[0] + drift * np.arange(len(train))\n",
        "        return predictions, fitted\n",
        "    \n",
        "    @staticmethod\n",
        "    def fit_rolling_mean_model(train: pd.Series, test_length: int, window: int = 4) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        rolling_mean = train.rolling(window=window).mean()\n",
        "        last_value = rolling_mean.iloc[-1] if not pd.isna(rolling_mean.iloc[-1]) else train.mean()\n",
        "        return np.full(test_length, last_value), rolling_mean.fillna(train.mean()).values\n",
        "    \n",
        "    @staticmethod\n",
        "    def fit_seasonal_naive(train: pd.Series, test_length: int, seasonality: int = 7) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        seasonal_value = train.iloc[-seasonality] if len(train) >= seasonality else train.iloc[-1]\n",
        "        return np.full(test_length, seasonal_value), np.full(len(train), seasonal_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "9d226c14",
      "metadata": {},
      "outputs": [],
      "source": [
        "class StatisticalModels:\n",
        "    @staticmethod\n",
        "    def fit_autoregressive_model(train: pd.Series, test_length: int, lags: int = 5) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        try:\n",
        "            if len(train) <= lags:\n",
        "                return BaselineModels.fit_rolling_mean_model(train, test_length, window=min(lags, len(train)))\n",
        "            \n",
        "            ar_model = AutoReg(train, lags=lags, old_names=False)\n",
        "            ar_result = ar_model.fit()\n",
        "            \n",
        "            predictions = ar_result.forecast(steps=test_length)\n",
        "            fitted_values = ar_result.fittedvalues\n",
        "            \n",
        "            if len(predictions) < test_length:\n",
        "                predictions = np.concatenate([predictions, np.repeat(predictions[-1], test_length - len(predictions))])\n",
        "            \n",
        "            if len(fitted_values) < len(train):\n",
        "                fitted_values = np.concatenate([np.full(len(train) - len(fitted_values), np.nan), fitted_values])\n",
        "            \n",
        "            print(f\"  Modelo AR({lags}) - AIC: {ar_result.aic:.2f}\")\n",
        "            return predictions, fitted_values\n",
        "        except Exception as e:\n",
        "            print(f\"  Erro no modelo AR: {e}\")\n",
        "            return BaselineModels.fit_rolling_mean_model(train, test_length, window=lags)\n",
        "    \n",
        "    @staticmethod\n",
        "    def fit_exponential_smoothing(train: pd.Series, test_length: int, seasonal_period: int = 7) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        try:\n",
        "            if seasonal_period > 0 and len(train) < 2 * seasonal_period:\n",
        "                seasonal_period = None\n",
        "            \n",
        "            if seasonal_period:\n",
        "                exp_model = ExponentialSmoothing(train, seasonal_periods=seasonal_period, initialization_method='estimated')\n",
        "            else:\n",
        "                exp_model = ExponentialSmoothing(train, initialization_method='estimated')\n",
        "            \n",
        "            exp_result = exp_model.fit()\n",
        "            predictions = exp_result.forecast(steps=test_length)\n",
        "            fitted_values = exp_result.fittedvalues\n",
        "            \n",
        "            if len(predictions) < test_length:\n",
        "                predictions = np.concatenate([predictions, np.repeat(predictions[-1], test_length - len(predictions))])\n",
        "            \n",
        "            if len(fitted_values) < len(train):\n",
        "                fitted_values = np.concatenate([np.full(len(train) - len(fitted_values), np.nan), fitted_values])\n",
        "            \n",
        "            print(f\"  Modelo Exponencial - AIC: {exp_result.aic:.2f}\")\n",
        "            return predictions, fitted_values\n",
        "        except Exception as e:\n",
        "            print(f\"  Erro no modelo exponencial: {e}\")\n",
        "            return BaselineModels.fit_rolling_mean_model(train, test_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "fb578cf2",
      "metadata": {},
      "outputs": [],
      "source": [
        "class RegressionModels:\n",
        "    @staticmethod\n",
        "    def prepare_covariates(train_data: pd.DataFrame, test_data: pd.DataFrame, target_col: str = 'volume') -> Tuple[pd.DataFrame, pd.DataFrame, List[str]]:\n",
        "        covariate_cols = []\n",
        "        train_data = train_data.copy()\n",
        "        test_data = test_data.copy()\n",
        "        \n",
        "        for col in train_data.columns:\n",
        "            if col != target_col and col != 'week':\n",
        "                if pd.api.types.is_numeric_dtype(train_data[col]):\n",
        "                    covariate_cols.append(col)\n",
        "                elif train_data[col].dtype == bool:\n",
        "                    train_data[col] = train_data[col].astype(int)\n",
        "                    test_data[col] = test_data[col].astype(int)\n",
        "                    covariate_cols.append(col)\n",
        "        \n",
        "        if not covariate_cols:\n",
        "            for lag in [1, 2, 3]:\n",
        "                train_data[f'lag{lag}'] = train_data[target_col].shift(lag).fillna(train_data[target_col].mean())\n",
        "                test_data[f'lag{lag}'] = test_data[target_col].shift(lag).fillna(train_data[target_col].mean())\n",
        "            covariate_cols = [f'lag{lag}' for lag in [1, 2, 3]]\n",
        "        \n",
        "        X_train = train_data[covariate_cols].fillna(train_data[covariate_cols].mean())\n",
        "        X_test = test_data[covariate_cols].fillna(train_data[covariate_cols].mean())\n",
        "        \n",
        "        return X_train, X_test, covariate_cols\n",
        "    \n",
        "    @staticmethod\n",
        "    def fit_regression_model(train_data: pd.DataFrame, test_data: pd.DataFrame, target_col: str = 'volume') -> Tuple[np.ndarray, np.ndarray]:\n",
        "        try:\n",
        "            X_train, X_test, covariate_cols = RegressionModels.prepare_covariates(train_data, test_data, target_col)\n",
        "            y_train = train_data[target_col].values\n",
        "            \n",
        "            min_len = min(len(X_train), len(y_train))\n",
        "            X_train = X_train.iloc[:min_len]\n",
        "            y_train = y_train[:min_len]\n",
        "            \n",
        "            if len(X_train) < 2:\n",
        "                return BaselineModels.fit_mean_model(train_data[target_col], len(test_data))\n",
        "            \n",
        "            model = OLS(y_train, X_train)\n",
        "            result = model.fit()\n",
        "            \n",
        "            predictions = result.predict(X_test)\n",
        "            fitted_values = result.fittedvalues\n",
        "            \n",
        "            if len(fitted_values) < len(train_data):\n",
        "                fitted_values = np.concatenate([np.full(len(train_data) - len(fitted_values), np.nan), fitted_values])\n",
        "            \n",
        "            print(f\"  Modelo Regressão - R²: {result.rsquared:.4f}\")\n",
        "            return predictions, fitted_values\n",
        "        except Exception as e:\n",
        "            print(f\"  Erro no modelo regressão: {e}\")\n",
        "            return BaselineModels.fit_mean_model(train_data[target_col], len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "3dc80d84",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelComparator:\n",
        "    @staticmethod\n",
        "    def calculate_model_metrics(all_results: Dict) -> pd.DataFrame:\n",
        "        \"\"\"Calcula métricas para todos os modelos\"\"\"\n",
        "        metrics_data = []\n",
        "        for model_name, model_data in all_results.items():\n",
        "            results = model_data['results']\n",
        "            \n",
        "            rmse = results['descriptive_stats']['rmse']\n",
        "            mae = results['descriptive_stats']['mae']\n",
        "            mse = results['descriptive_stats']['mse']\n",
        "            \n",
        "            criteria_names = ['Normalidade', 'Autocorrelação', 'Homocedasticidade', 'Durbin-Watson', 'Média Zero']\n",
        "            criteria_results = [\n",
        "                results['normality_ad']['is_normal'],\n",
        "                results['ljung_box']['no_autocorr'],\n",
        "                results['arch_test']['is_homoscedastic'],\n",
        "                results['durbin_watson']['no_autocorr'],\n",
        "                results['mean_test']['mean_zero']\n",
        "            ]\n",
        "            \n",
        "            criteria_met = sum(1 for r in criteria_results if not np.isnan(r) and r)\n",
        "            criteria_total = sum(1 for r in criteria_results if not np.isnan(r))\n",
        "            \n",
        "            criteria_status = []\n",
        "            for r in criteria_results:\n",
        "                if np.isnan(r):\n",
        "                    criteria_status.append('N/A')\n",
        "                elif r:\n",
        "                    criteria_status.append('OK')\n",
        "                else:\n",
        "                    criteria_status.append('FALHA')\n",
        "            \n",
        "            metrics_data.append({\n",
        "                'Modelo': model_name,\n",
        "                'RMSE': rmse,\n",
        "                'MAE': mae,\n",
        "                'MSE': mse,\n",
        "                'Critérios_Atendidos': f\"{criteria_met}/{criteria_total}\",\n",
        "                'Score_Qualidade': criteria_met / criteria_total if criteria_total > 0 else 0,\n",
        "                'Normalidade': criteria_status[0],\n",
        "                'Autocorrelação': criteria_status[1],\n",
        "                'Homocedasticidade': criteria_status[2],\n",
        "                'Durbin_Watson': criteria_status[3],\n",
        "                'Média_Zero': criteria_status[4]\n",
        "            })\n",
        "        \n",
        "        return pd.DataFrame(metrics_data)\n",
        "\n",
        "    @staticmethod\n",
        "    def rank_models_by_error(metrics_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        if metrics_df.empty:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        ranked_df = metrics_df.sort_values('RMSE').reset_index(drop=True)\n",
        "        ranked_df['Rank'] = range(1, len(ranked_df) + 1)\n",
        "        ranked_df['Rank_MAE'] = ranked_df['MAE'].rank(method='min')\n",
        "        ranked_df['Rank_MSE'] = ranked_df['MSE'].rank(method='min')\n",
        "        ranked_df['Rank_Combinado'] = (ranked_df['Rank'] + ranked_df['Rank_MAE'] + ranked_df['Rank_MSE']) / 3\n",
        "        \n",
        "        ranked_df = ranked_df.sort_values('Rank_Combinado').reset_index(drop=True)\n",
        "        ranked_df['Rank_Final'] = range(1, len(ranked_df) + 1)\n",
        "        \n",
        "        return ranked_df\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_model_comparison(ranked_df: pd.DataFrame):\n",
        "        \"\"\"Plota comparação entre modelos com novo layout solicitado\"\"\"\n",
        "        \n",
        "        fig = plt.figure(figsize=(18, 12))\n",
        "        \n",
        "        # --- GRID: 2 colunas em cima, 1 linha inteira embaixo ---\n",
        "        gs = fig.add_gridspec(2, 2, height_ratios=[1, 1.2])\n",
        "        \n",
        "        ax_left = fig.add_subplot(gs[0, 0])   # gráfico horizontal\n",
        "        ax_right = fig.add_subplot(gs[0, 1])  # tabela / sumário\n",
        "        ax_bottom = fig.add_subplot(gs[1, :]) # gráfico de barras vertical        \n",
        "        \n",
        "        # ---- GRÁFICO 1: barras horizontais ----\n",
        "        colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(ranked_df)))\n",
        "        bars = ax_left.barh(\n",
        "            range(len(ranked_df)),\n",
        "            ranked_df['RMSE'],\n",
        "            color=colors,\n",
        "            edgecolor='black'\n",
        "        )\n",
        "        ax_left.set_yticks(range(len(ranked_df)))\n",
        "        ax_left.set_yticklabels([f\"{r}. {m}\" for r, m in zip(ranked_df['Rank_Final'], ranked_df['Modelo'])])\n",
        "        ax_left.set_xlabel('RMSE (menor é melhor)')\n",
        "        ax_left.set_title('RMSE por Modelo - Ranking')\n",
        "        ax_left.invert_yaxis()\n",
        "        \n",
        "        for bar, rmse in zip(bars, ranked_df['RMSE']):\n",
        "            ax_left.text(rmse * 1.01, bar.get_y() + bar.get_height()/2,\n",
        "                         f'{rmse:.4f}', va='center', fontsize=9)\n",
        "        \n",
        "        # ---- GRÁFICO 2: tabela ----\n",
        "        ax_right.axis('off')\n",
        "        table_data = []\n",
        "        \n",
        "        for _, row in ranked_df.iterrows():\n",
        "            table_data.append([\n",
        "                f\"{row['Rank_Final']}\",\n",
        "                row['Modelo'],\n",
        "                f\"{row['RMSE']:.4f}\",\n",
        "                f\"{row['MAE']:.4f}\",\n",
        "                f\"{row['Critérios_Atendidos']}\"\n",
        "            ])\n",
        "        \n",
        "        text = \"RANKING FINAL DE MODELOS\\n\"\n",
        "        text += \"=\" * 60 + \"\\n\"\n",
        "        text += f\"{'Rank':<5} {'Modelo':<20} {'RMSE':<10} {'MAE':<10}\\n\"\n",
        "        text += \"-\" * 60 + \"\\n\"\n",
        "        \n",
        "        for row in table_data:\n",
        "            text += f\"{row[0]:<5} {row[1]:<20} {row[2]:<10} {row[3]:<10}\\n\"\n",
        "        \n",
        "        best = ranked_df.iloc[0]\n",
        "        text += \"\\n\" + \"=\" * 60 + \"\\n\"\n",
        "        text += f\"MELHOR MODELO: {best['Modelo']}\\n\"\n",
        "        text += f\"RMSE: {best['RMSE']:.4f} | MAE: {best['MAE']:.4f}\\n\"\n",
        "        text += f\"Critérios atendidos: {best['Critérios_Atendidos']}\"\n",
        "        \n",
        "        ax_right.text(0.05, 0.95, text, transform=ax_right.transAxes, \n",
        "                      fontsize=16, fontfamily='monospace', va='top')\n",
        "        \n",
        "        # ---- GRÁFICO 3: barras verticais (embaixo) ----\n",
        "        x = np.arange(len(ranked_df))\n",
        "        width = 0.25\n",
        "        \n",
        "        ax_bottom.bar(x - width, ranked_df['RMSE'], width, label='RMSE', alpha=0.7)\n",
        "        ax_bottom.bar(x, ranked_df['MAE'], width, label='MAE', alpha=0.7)\n",
        "        ax_bottom.bar(x + width, ranked_df['MSE'], width, label='MSE', alpha=0.7)\n",
        "        \n",
        "        ax_bottom.set_xlabel('Modelos (rank final)')\n",
        "        ax_bottom.set_ylabel('Valor')\n",
        "        ax_bottom.set_title('Comparação de Métricas de Erro')\n",
        "        \n",
        "        ax_bottom.set_xticks(x)\n",
        "        ax_bottom.set_xticklabels([f\"{r}\" for r in ranked_df['Rank_Final']])\n",
        "        ax_bottom.legend()\n",
        "        ax_bottom.grid(True, alpha=0.3, axis='y')\n",
        "        \n",
        "        plt.suptitle(\n",
        "            'COMPARAÇÃO E RANKING DE MODELOS - MENOR ERRO (RMSE) É MELHOR',\n",
        "            fontsize=15, fontweight='bold'\n",
        "        )\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Console output igual ao original\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"RANKING FINAL DE MODELOS (ordenado por RMSE - menor é melhor)\")\n",
        "        print(\"=\"*80)\n",
        "        print(ranked_df[['Rank_Final', 'Modelo', 'RMSE', 'MAE']].to_string(index=False))\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\" MELHOR MODELO: {ranked_df.iloc[0]['Modelo']}\")\n",
        "        print(f\"   RMSE: {ranked_df.iloc[0]['RMSE']:.4f}\")\n",
        "        print(f\"   MAE:  {ranked_df.iloc[0]['MAE']:.4f}\")\n",
        "        print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "3541f32a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# FUNÇÃO PRINCIPAL\n",
        "def execute_complete_analysis(file_path: str, target_column: str = 'volume', test_size: float = 0.2):\n",
        "    print(\"=\"*80)\n",
        "    print(\"ANÁLISE COMPLETA DE MODELOS DE PREVISÃO\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # 1. Carregar dados\n",
        "    print(\"\\n1. CARREGANDO DADOS...\")\n",
        "    try:\n",
        "        data = pd.read_csv(file_path)\n",
        "        if 'week' in data.columns:\n",
        "            data['week'] = pd.to_datetime(data['week'])\n",
        "            data = data.sort_values('week')\n",
        "        print(f\"   Dataset: {data.shape[0]} linhas, {data.shape[1]} colunas\")\n",
        "        print(f\"   Colunas: {list(data.columns)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   Erro: {e}\")\n",
        "        return None, None, None\n",
        "    \n",
        "    # 2. Dividir dados\n",
        "    print(\"\\n2. DIVIDINDO DADOS...\")\n",
        "    train_size = int(len(data) * (1 - test_size))\n",
        "    train = data.iloc[:train_size].copy()\n",
        "    test = data.iloc[train_size:].copy()\n",
        "    print(f\"   Treino: {len(train)} amostras\")\n",
        "    print(f\"   Teste:  {len(test)} amostras\")\n",
        "    \n",
        "    # 3. Ajustar modelos\n",
        "    print(\"\\n3. AJUSTANDO MODELOS...\")\n",
        "    models_predictions = {}\n",
        "    test_length = len(test)\n",
        "    \n",
        "    # Baseline\n",
        "    print(\"\\n   A. MODELOS BASELINE:\")\n",
        "    models = [\n",
        "        ('Mean', BaselineModels.fit_mean_model),\n",
        "        ('Naive', BaselineModels.fit_naive_model),\n",
        "        ('Drift', BaselineModels.fit_drift_model),\n",
        "        ('RollingMean_k4', lambda t, tl: BaselineModels.fit_rolling_mean_model(t, tl, 4)),\n",
        "        ('SeasonalNaive', lambda t, tl: BaselineModels.fit_seasonal_naive(t, tl, 7))\n",
        "    ]\n",
        "    \n",
        "    for name, func in models:\n",
        "        pred, fitted = func(train[target_column], test_length)\n",
        "        models_predictions[name] = pred\n",
        "        models_predictions[f'{name}_fitted'] = fitted\n",
        "        print(f\"     {name} ajustado\")\n",
        "    \n",
        "    # Estatísticos\n",
        "    print(\"\\n   B. MODELOS ESTATÍSTICOS:\")\n",
        "    pred, fitted = StatisticalModels.fit_autoregressive_model(train[target_column], test_length, 5)\n",
        "    models_predictions['AutoReg_AR5'] = pred\n",
        "    models_predictions['AutoReg_AR5_fitted'] = fitted\n",
        "    \n",
        "    pred, fitted = StatisticalModels.fit_exponential_smoothing(train[target_column], test_length)\n",
        "    models_predictions['ExponentialSmoothing'] = pred\n",
        "    models_predictions['ExponentialSmoothing_fitted'] = fitted\n",
        "    \n",
        "    # Regressão\n",
        "    print(\"\\n   C. MODELOS DE REGRESSÃO:\")\n",
        "    pred, fitted = RegressionModels.fit_regression_model(train, test, target_column)\n",
        "    models_predictions['Regression'] = pred\n",
        "    models_predictions['Regression_fitted'] = fitted\n",
        "    \n",
        "    # 4. Análise de resíduos\n",
        "    print(\"\\n4. ANÁLISE DE RESÍDUOS...\")\n",
        "    results_dir = Path(\"./residuals_analysis\")\n",
        "    results_dir.mkdir(exist_ok=True)\n",
        "    all_results = {}\n",
        "    \n",
        "    for model_name in ['Mean', 'Naive', 'Drift', 'RollingMean_k4', 'SeasonalNaive', \n",
        "                      'AutoReg_AR5', 'ExponentialSmoothing', 'Regression']:\n",
        "        \n",
        "        print(f\"\\n   Analisando: {model_name}\")\n",
        "        fitted_key = f\"{model_name}_fitted\"\n",
        "        \n",
        "        if fitted_key in models_predictions:\n",
        "            fitted_values = np.array(models_predictions[fitted_key])\n",
        "            \n",
        "            # Tratar dimensões inconsistentes\n",
        "            if np.isnan(fitted_values).any():\n",
        "                mask = ~np.isnan(fitted_values)\n",
        "                if mask.sum() > 0:\n",
        "                    fitted_clean = fitted_values[mask]\n",
        "                    train_clean = train[target_column].values[mask]\n",
        "                    \n",
        "                    if len(fitted_clean) == len(train_clean):\n",
        "                        residuals = train_clean - fitted_clean\n",
        "                        actual_values = train_clean\n",
        "                    else:\n",
        "                        min_len = min(len(fitted_clean), len(train_clean))\n",
        "                        residuals = train_clean[:min_len] - fitted_clean[:min_len]\n",
        "                        actual_values = train_clean[:min_len]\n",
        "                else:\n",
        "                    print(f\"     Aviso: Todos valores são NaN\")\n",
        "                    continue\n",
        "            else:\n",
        "                # Sem NaN - verificar dimensões\n",
        "                if len(fitted_values) != len(train):\n",
        "                    min_len = min(len(fitted_values), len(train))\n",
        "                    residuals = train[target_column].values[:min_len] - fitted_values[:min_len]\n",
        "                    actual_values = train[target_column].values[:min_len]\n",
        "                else:\n",
        "                    residuals = train[target_column].values - fitted_values\n",
        "                    actual_values = train[target_column].values\n",
        "        else:\n",
        "            predictions = np.array(models_predictions[model_name])\n",
        "            if len(predictions) != len(test):\n",
        "                predictions = predictions[:len(test)] if len(predictions) > len(test) else np.concatenate([predictions, np.repeat(predictions[-1], len(test) - len(predictions))])\n",
        "            \n",
        "            residuals = test[target_column].values - predictions\n",
        "            actual_values = test[target_column].values\n",
        "            fitted_values = predictions\n",
        "        \n",
        "        if len(residuals) < 5:\n",
        "            print(f\"     Poucos dados: {len(residuals)} resíduos\")\n",
        "            continue\n",
        "        \n",
        "        # Garantir que fitted_values tenha o mesmo tamanho que residuals\n",
        "        if len(fitted_values) > len(residuals):\n",
        "            fitted_values = fitted_values[:len(residuals)]\n",
        "        elif len(fitted_values) < len(residuals):\n",
        "            fitted_values = np.concatenate([fitted_values, np.full(len(residuals) - len(fitted_values), np.nan)])\n",
        "        \n",
        "        analyzer = ResidualAnalysis(model_name, residuals, fitted_values, actual_values)\n",
        "        save_path = results_dir / f\"residuals_{model_name.lower().replace(' ', '_')}.png\"\n",
        "        lags = min(10, len(residuals)//3)\n",
        "        results = analyzer.comprehensive_residual_analysis(lags=lags, save_path=save_path)\n",
        "        \n",
        "        all_results[model_name] = {'results': results, 'residuals': residuals}\n",
        "    \n",
        "    if not all_results:\n",
        "        print(\"Nenhum modelo analisado.\")\n",
        "        return None, None, None\n",
        "    \n",
        "    # 5. Comparação e Ranking\n",
        "    print(\"\\n5. COMPARAÇÃO E RANKING DE MODELOS...\")\n",
        "    metrics_df = ModelComparator.calculate_model_metrics(all_results)\n",
        "    ranked_df = ModelComparator.rank_models_by_error(metrics_df)\n",
        "    ModelComparator.plot_model_comparison(ranked_df)\n",
        "    print(f\"\\n Análise concluída!\")\n",
        "    \n",
        "    return all_results, ranked_df, metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "d4d1c619",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ANÁLISE COMPLETA DE MODELOS DE PREVISÃO\n",
            "================================================================================\n",
            "\n",
            "1. CARREGANDO DADOS...\n",
            "   Erro: [Errno 2] No such file or directory: 'data_updated.csv'\n"
          ]
        }
      ],
      "source": [
        "results = execute_complete_analysis(\"data_updated.csv\", target_column=\"volume\", test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Dl3SF8oeZoWb",
      "metadata": {
        "id": "Dl3SF8oeZoWb"
      },
      "source": [
        "#"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
